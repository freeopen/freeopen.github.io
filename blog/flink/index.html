<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>冠军方案之 Apache Flink 极客挑战赛 | Freeopen</title>
  <meta name="title" content="冠军方案之 Apache Flink 极客挑战赛">
<meta name="description" content="7 labo.">
<meta name="referrer" content="strict-origin-when-cross-origin">
  <link href="/main.css" rel="stylesheet">
</head>
<body>
  <header>
  <a href="/" class="title">
    <h1>Freeopen</h1>
  </a>
  <nav aria-label="site">
      <a href="/">Home</a>
      <a href="/blog/">Blog</a>
      <a href="/shorttips/">Tips</a>
      <a href="/about/">About</a>
  </nav>
</header>


  <div>
      

      <h1>冠军方案之 Apache Flink 极客挑战赛</h1>
      <time datetime="2021-02-10" class="post-date">
          2021-02-10
          
            (updated on 2021-02-10)
          
      </time>
  <main>
    <blockquote>
<p>冠军：合肥工大 SkyPeaceLL</p>
</blockquote>
<h2 id="bi-sai-ren-wu">比赛任务</h2>
<h3 id="shu-ju-ji">数据集</h3>
<p><strong>新冠病例行动数据集</strong></p>
<ul>
<li>病例历史行动数据集（训练集1） 1M+</li>
<li>确诊病例数据 （测试集1） 500+</li>
<li>实时病例行动数据集（测试集2） 1000+</li>
<li>人脸特征512维</li>
</ul>
<p><strong>天猫精灵行为数据集</strong></p>
<ul>
<li>天猫精灵历史行为数据集（训练集2） 1M+</li>
<li>用户行为数据集（测试集3） 500+</li>
<li>实时用户行为数据集（测试集4） 1000+</li>
<li>行为特征700维</li>
</ul>
<h3 id="si-ge-ren-wu"><strong>四个任务</strong></h3>
<ul>
<li>根据测试集1每条数据的特征向量，在训练集1中找出该病例（人）对应的所有记录。</li>
<li>对测试集2的每条数据，根据其特征向量进行实时分类（人）。</li>
<li>根据测试集3每条数据的特征向量，在训练集2中找出该用户行为（领域+意图）对应的所有记录。</li>
<li>对测试集4的每条数据，根据其特征向量进行实时分类（领域+意图）。</li>
</ul>
<h3 id="xing-neng-yao-qiu"><strong>性能要求</strong></h3>
<ul>
<li>
<p>四个任务总运行时间不能超过3小时。</p>
</li>
<li>
<p>对每条实时数据完成实时分类的响应时间不能超过500ms。</p>
</li>
<li>
<p><strong>平台和组件</strong></p>
<ul>
<li>Flink，PyFlink，Flink ai_flow，Proxima，Intel Zoo cluster serving</li>
</ul>
</li>
</ul>
<h2 id="gong-zuo-liu">工作流</h2>
<p><img src="/blog/flink/flink-workflow.png" alt="flink-workflow" /></p>
<p>官方提供一套docker环境及baseline代码，由于新冠病例和天猫精灵在算法任务上的相似性，编写两个 workflow 配置文件(yaml)，使得一套python代码运行两个算法。</p>
<p>基本思路：</p>
<ol>
<li>并发读入100万条训练集（并发100），训练AutoEncoder模型，为高维特征降维；</li>
<li>用训练好的模型对特征向量降维（并发16）；</li>
<li>用Proxima HnswBuilder 对降维后的特征向量创建索引；</li>
<li>对测试集1中的样本选出Top1024+1（样本）个候选者；</li>
<li>对候选者进行聚类（算法：Chinese Whisper），得出任务1的结果</li>
<li>从kafka读取测试集2，选出Top1，并以对应UUID作为分类label， 得出任务2的结果。</li>
</ol>
<h2 id="shu-ju-yu-chu-li">数据预处理</h2>
<p><strong>病例行动数据集</strong>
不含异常数据，且特征向量已经L2 Normalization，不需要特别的预处理。</p>
<p><strong>天猫精灵行为数据集</strong></p>
<p>存在一些异常数据，需要做以下预处理：</p>
<p>移除某些特征向量数据末尾多出的空格（注：如果不做相应处理，score3通常得0分）</p>
<p>Re-generate UUID for duplicated UUID</p>
<p>Processing zero vector</p>
<p>Processing duplicated vector</p>
<p>L2 Normalization</p>
<h2 id="mo-xing-xun-lian">模型训练</h2>
<p><strong>目标：对特征向量降维</strong></p>
<p>算法比较：</p>
<ol>
<li>Simple AutoEncoder （实测效果好，稳定，性能好，采用）</li>
<li>Deep AutoEncoder（实测效果好，性能一般，最终未采用）</li>
<li>VAE (Variational AutoEncoder) （实测效果相对较差，未采用）</li>
<li>PCA (Principal Component Analysis) （实测效果相对较差，未采用）</li>
<li>NMF (Non-negative matrix factorization) （实测效果相对较差，未采用）</li>
</ol>
<p>模型参数</p>
<ol>
<li>Loss Function: MSE</li>
<li>Active Function: Linear</li>
</ol>
<p>维度选择</p>
<ol>
<li>新冠病例： 512 =&gt; 128</li>
<li>天猫精灵： 700 =&gt; 128</li>
</ol>
<h2 id="ji-shu-zhan-xing-neng-zhi-biao">技术栈性能指标</h2>
<p><strong>Intel Zoo Cluster Serving</strong></p>
<ol>
<li>支持Tensorflow Saved Model 以及PyTorch Model for Inference</li>
<li>支持并发Inference（本赛题设置为16个并发），在多并发下运行稳定</li>
<li>模型针对CPU做了优化，无需GPU环境</li>
<li>自动生成配置，方便部署</li>
<li>响应时间短。平均每个请求响应时间实测小于35ms，充分满足本方案中的性能需求。</li>
</ol>
<p><strong>达摩院proxima</strong></p>
<ol>
<li>使用Proxima HnswBuilder 创建索引，使用HnswSearch search vector</li>
<li>支持海量数据向量检索</li>
<li>召回率高，Top100 召回率超过98.5%</li>
<li>检索性能高，在本赛题中，平均每个请求(TopK=1024)的响应时间小于3ms，完全满足TopK筛选+再聚类这样类型的应用需求，对于实时的向量检索也毫无压力。</li>
</ol>
<h2 id="online-data-kafka-chao-shi-wen-ti">Online Data (kafka) 超时问题</h2>
<p>按参考代码标准流程，可能是初始化较慢的原因，在开始时有8秒延迟，将导致16条数据被超时。</p>
<p><strong>方法一、使用ai_flow 内建的算子</strong></p>
<ol>
<li>
<p>使用<code>ai_flow.read_example</code>、<code>ai_flow.predict</code>、<code>ai_flow.transform</code>和<code>ai_flow.write_example</code></p>
</li>
<li>
<p>在其中的<code>SourceExecutor/SinkExecutor</code>实现类中使用PyFlink TABLE API(For Kafka) 读/写Kafka Topic</p>
</li>
<li>
<p>为相应Flink job的<code>StreamExecutionEnvironment</code>设置参数：<code>stream_env.enable_checkpointing(250)</code>
该参数默认为<code>3000ms</code>，<code>3000ms</code>会导致每3秒才集中从Kafka Topic中读出6条数据。所以，如果不设置这个参数，必定会导致每6条数据中平均有5条会超时500ms，使得实时数据(score2和score4)得分很难超过100分（满分500分），因此必须改变这个参数设置。针对本赛题，可以设置为<code>250ms</code>。</p>
<p>方法一在产线上应用没什么问题，但是在本比赛中它有一个小问题，那就是初始会有8秒延迟，这个延迟会使得赛题程序开始发送的约16条数据被TABLE API(For Kafka)读到时都会超时500ms，从而对最终评分有所影响（实测大概影响6分左右）。
使用方法一可确保只会有少量的初始数据（实测16条左右）产生超时。</p>
</li>
</ol>
<p><strong>方法二、使用ai_flow的用户自定义算子</strong></p>
<ol>
<li>ai_flow支持更为灵活的用户自定义算子<code>af.user_define_operation</code></li>
<li>在用户自定义算子的Executor实现类中，直接使用Kafka Consumer/Producer 读写Kafka Topic</li>
<li>直接通过 Kafka consumer从Kafka Topic读取数据，然后call Inference API (by Zoo cluster serving) 降维，然后使用Proxima search API search Top1 UUID，然后得出分类label，最后直接通过Kafka Producer 将结果数据写入Kafka Topic。
使用方法二可避免初始16条数据的超时问题，设置好关键参数 (如<code>fetch_max_wait_ms=200</code>)，可确保所有数据都不会超时。</li>
</ol>

  </main>
  <p>
        Categories:
          <a href="/categories/ji-qi-xue-xi/">#机器学习</a>
        Tags:
          <a href="/tags/top1/">#top1</a>
  </p>
  <hr>
  <section>
      <h2 id="comments" class="">Comments</h2>

      
          
      
      
    
    
    

    
        
        
    

    <p class="comment-note">
        你有问题需要解决，想要分享反馈，或者讨论更多的想法吗？请随时在这里留下评论！ 这个讨论将与 <a href="https://github.com/freeopen/freeopen.github.io/discussions/categories/post-comments?discussions_q=%22%E5%86%A0%E5%86%9B%E6%96%B9%E6%A1%88%E4%B9%8B%20Apache%20Flink%20%E6%9E%81%E5%AE%A2%E6%8C%91%E6%88%98%E8%B5%9B%22%20in%3Atitle"><em>discussion on GitHub</em></a> 直接连接，所以你也可以直接在那边发表评论

    </p>

    <div class="giscus"></div>

    <script src="https://giscus.app/client.js"
        data-repo="freeopen/freeopen.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnkxNjg3MTUxNzE="
        data-category="Post Comments"
        data-category-id="DIC_kwDOCg5jo84CpXQC"
    
        data-mapping="specific"
    
        data-term="冠军方案之 Apache Flink 极客挑战赛"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
    </script>


  </section>

  </div><footer class="footer">
    <hr>
    <small>
        &copy; <time id="dynamic-year" datetime="2017">2017</time>. All rights reserved.
    </small>
</footer>
<script>
    const currentYear = new Date().getFullYear();

    const timeElement = document.getElementById('dynamic-year');
    timeElement.textContent = `2017 - ${currentYear}`;
    timeElement.setAttribute('datetime', `2017/${currentYear}`);
</script>
</body>
</html>
